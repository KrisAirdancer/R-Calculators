---
title: "Calculators"
author: "Chris Marston"
date: "2/14/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Calculators

**WORKSPACE**

```{r, echo=FALSE, cache=TRUE}
# ***** SHAKESPEARE BYTES *****

sbytes_min = round(min(shakespeare_bytes$bytes))
sbytes_max = round(max(shakespeare_bytes$bytes))

# Taking samplemeans
hist(shakespeare_bytes$bytes,
     breaks=255,
     freq=FALSE,
     main="Shakespeare Bytes",
     xlab="Value of byte")

samplesCount = 2000
sampleSize = 2
SSB_N2_Samplemeans = rep(NA, samplesCount)
for (item in 1:samplesCount) {
  SSB_N2_Samplemeans[item] = mean(shakespeare_bytes[sample(nrow(shakespeare_bytes), sampleSize), ])
}

hist(SSB_N2_Samplemeans,
     breaks=255,
     freq=FALSE,
     main="Shakespeare Bytes - sampleSize = 2",
     xlab="Value of byte")

samplesCount = 2000
sampleSize = 4
SSB_N4_Samplemeans = rep(NA, samplesCount)
for (item in 1:samplesCount) {
  SSB_N4_Samplemeans[item] = mean(shakespeare_bytes[sample(nrow(shakespeare_bytes), sampleSize), ])
}

hist(SSB_N4_Samplemeans,
     breaks=255,
     freq=FALSE,
     main="Shakespeare Bytes - sampleSize = 4",
     xlab="Value of byte")

samplesCount = 2000
sampleSize = 8
SSB_N8_Samplemeans = rep(NA, samplesCount)
for (item in 1:samplesCount) {
  SSB_N8_Samplemeans[item] = mean(shakespeare_bytes[sample(nrow(shakespeare_bytes), sampleSize), ])
}

hist(SSB_N8_Samplemeans,
     breaks=255,
     freq=FALSE,
     main="Shakespeare Bytes - sampleSize = 8",
     xlab="Value of byte")

samplesCount = 2000
sampleSize = 16
SSB_N16_Samplemeans = rep(NA, samplesCount)
for (item in 1:samplesCount) {
  SSB_N16_Samplemeans[item] = mean(shakespeare_bytes[sample(nrow(shakespeare_bytes), sampleSize), ])
}
plot(min(SSB_N16_Samplemeans):max(SSB_N16_Samplemeans),
     dnorm(min(SSB_N16_Samplemeans):max(SSB_N16_Samplemeans),
           mean=mean(SSB_N16_Samplemeans),
           sd=sd(SSB_N16_Samplemeans)),
     main="Shakespeare Bytes - sampleSize = 16 vs Normal",
     xlab="Value of byte",
     ylab="Density",
     ylim=c(0,0.07)
)
hist(SSB_N16_Samplemeans,
     breaks=255,
     col=rgb(0,0,0,alpha=0.1),
     freq=FALSE,
     add=TRUE
)
```

```{r}





carbon_data = c(co2)

mean_emiss = mean(co2)
qt(0.99, co2)

carbon_CI = mean(co2) - (2.576 * (sd(co2) / sqrt(length(co2))))
mean(co2)
length(c(co2))
sd(co2)


c(co2)


E_of_X = function(probs, vals) {
  return(sum(vals*probs))
}

E_of_X(dunif())
```


**POISSON CALCULATIONS**
```{r}
dpois(147, 160)
ppois(0.03, 4)
```
**POISSON NOTES**
`dpois(x, lambda)` is the probability of x successes in a period when the expected number of events is lambda.
`ppois(q, lambda, lower.tail)` is the cumulative probability (lower.tail = TRUE for left tail, lower.tail = FALSE for right tail) of less than or equal to q successes.
`rpois(n, lambda)` returns n random numbers from the Poisson distribution x ~ P(lambda).
`qpois(p, lambda, lower.tail)` returns the value (quantile) at the specified cumulative probability (percentile) p.

**Confidnece Intervals**
```{r}
# CONFIDENCE INTERVAL USING binom.test()
#binom.test(numOfSuccesses, numOfTrials, confInterval)
binom.test(5000, 100000, conf.level=0.95) # ex. 500 successes out of 100,000 trials w/ a confidence interval of 95%

# CONFIDENCE INTERVAL USING prop.test()
prop.test(5000, 10000, conf.level=0.95)

# CONFIDENCE INTERVAL USING FISHER TEST (requires contingency table)
#contingency_table <- matrix(c(banner1_clicks, banner2_clicks, banner1_failures, banner2_failures), nrow=2)
contingency_table <- matrix(c(200, 180, 300, 420), nrow=2)

fisher.test(contingency_table, conf.level=0.98)

# POINT ESTIMATE
#(see lab10 section 8 - just above section 9)
# To compute a point estimate, simply calculate the mean or some other metric.
  # In lab, we took the number of successes (ad clicks) and divided by the total number of visitors. This gave us a point estimate of the ad-click rate.

# CORRELATION COEFFICIENT
# Notes
  # The correlation coefficient of two variables in a data set equals to their covariance divided by the product of their individual standard deviations. It is a normalized measurement of how the two are linearly related. 
    # [See here](http://www.r-tutor.com/elementary-statistics/numerical-measures/covariance)

  # The covariance of two variables x and y in a data set measures how the two are linearly related. A positive covariance would indicate a positive linear relationship between the variables, and a negative covariance would indicate the opposite. 
    # [See here](http://www.r-tutor.com/elementary-statistics/numerical-measures/correlation-coefficient)

  # R functions
    # [See here](http://www.sthda.com/english/wiki/correlation-test-between-two-variables-in-r)
    # cor() or cor.test():

# Steps to calculate:
  # 1. Calculate the covariance of each variable
  # 2. Calculate the standard deviations of each variable
  # 3. Calcualte teh correlation coefficient

```







**Other**
``` {r}
# Total number of outcomes:
  # Multiply the number of outcomes for each event together (RedBook p12)
# "Digits" are any numerals from 0 to 9. That is, 0 through 9 are all digits.
```

**Expected Value**
``` {r}

E_of_X = function(probs, vals) {
  return(sum(vals*probs))
}

Var_of_X = function(probs, vals) {
  return(sum((vals^2)*probs) - (E_of_X(probs, vals)^2))
}

Std_of_X = function(probs, vals) {
  return(sqrt(Var_of_X(probs, vals)))
}

probs1 = c(1/52, 1/51, 1/50, 1/49, 1/48)
vals1 = c(1:5)
probs2 = c(1/4, 1/12, 2/3)
vals2 = c(10, 25, -5)
probs3 = c(6/7, 1/7)
vals3 = c(0, 1)

# Expected value of 1
E_of_X(probs1, vals1)

# Variance of 1
Var_of_X(probs1, vals1)

# Standard Deviation of 1
Std_of_X(probs1, vals1)

# Expected value of 2
E_of_X(probs2, vals2)

# Variance of 2
Var_of_X(probs2, vals2)

# Standard Deviation of 2
Std_of_X(probs2, vals2)

# Expected value of 3
E_of_X(probs3, vals3)

# Variance of 3
Var_of_X(probs3, vals3)

# Standard Deviation of 3
Std_of_X(probs3, vals3)


```

**Bernoulli Distribution**
``` {r}


```

**Binomial Distribution**
``` {r}
probOfSuccess = c(0.91) # Probability of getting a question correct, etc.
probSize = 5 # Total number of questions answered, etc.
numTrials = 4 # Number of questions answered correctly, etc.

# Success on less than numOfTrials
LTNumTrials = c(0 : numTrials - 1)
sum(dbinom(LTNumTrials, probSize, probOfSuccess))

# Success on numTrials or less
LEQNumTrials = c(0 : numTrials)
sum(dbinom(LEQNumTrials, probSize, probOfSuccess))

# Success on exactly numOfTrials
dbinom(numTrials, probSize, probOfSuccess)

# Success on numOfTrials or more
GEQNumTrials = c(numTrials : probSize)
sum(dbinom(GEQNumTrials, probSize, probOfSuccess))

# Success on greater than numOfTrials
GTNumTrials = c(numTrials + 1 : probSize)
sum(dbinom(GTNumTrials, probSize, probOfSuccess))

```

**Other Calculations**
``` {r}
#Standard Deviation
sd(c(3.5, 3.4, 3.8, 3.6, 2.3))

# n choose k
choose(52, 4)/choose(52, 5)
```




